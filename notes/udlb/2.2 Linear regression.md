At this moment to train a model, we need
- Input x
- Output y
- L loss function
## 1D linear regression model
Here the models describe a relationships between the x input and the y output as a straight line
$$
\begin{align}
y &= f(x,\phi)\\
&= \phi_0 + \phi_1 x
\end{align}
$$
## Loss 
To decide what set of parameters are the best, we can capture the degree of mismatch between the predicted y and true y
$$
\mathcal{L}(\phi) = \hat{y}_\phi - y
$$

So, the loss L is a function of the parameters $\phi$ , in a linear regression we just have two parameters, so we can calculate the loss for every combination of values. The best parameters are at the minimum of this surface

### Training
The process of minimize the function L is called training or model fitting, or learning.
$$
\hat{\phi} = \arg\min_\phi  
$$
The common process to find the minimum is use the gradient walking down the function ultil reach the bottom.
