Supervised learning models define a mapping from input data to an output prediction.
Mathematically, to make a prediction (the computation we called *inference*) we need a model f that takes input x and return y.
$$
y = f(x)
$$
Indeed, the f function has parameters that determines the relations between the input data and the output, so we should really write, where $\phi$ represent the parameters.
$$
y = f(x, \phi)
$$

The procces of training a model is the attempt to find the best parameters $\phi$ that minimize the error between the output and the expected output, we measure or quantify this error or degree of mismatch with the loss function, that summarize how poorly the model predictsthe training outputs from their parameters $\phi$
Again, mathematically we have
$$
\hat{\phi} = \arg\min_\phi(L(\phi))
$$
With this minimization we have found a model parameters that accurately predict the training outputs from the training inputs

